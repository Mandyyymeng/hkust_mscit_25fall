<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>SFLM &#8212; SFLM  documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=5ecbeea2" />
    <link rel="stylesheet" type="text/css" href="_static/basic.css?v=b08954a9" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css?v=27fed22d" />
    <link rel="stylesheet" type="text/css" href="_static/graphviz.css?v=4ae1632d" />
    <script src="_static/documentation_options.js?v=5929fcd5"></script>
    <script src="_static/doctools.js?v=9bcbadda"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="API Reference" href="autoapi/index.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
          

          <div class="body" role="main">
            
  <section id="sflm">
<h1>SFLM<a class="headerlink" href="#sflm" title="Link to this heading">¶</a></h1>
<p>In this assignment, you will need to complete the code for a small language model for a formal language,
called Small Formal Language Model.
This small language model is implemented as a transformer as illustrated in the following figure.</p>
<figure class="align-default" id="id1">
<span id="structure"></span><a class="reference internal image-reference" href="_images/SFLM_architecture.png"><img alt="_images/SFLM_architecture.png" src="_images/SFLM_architecture.png" style="width: 40%;" />
</a>
<figcaption>
<p><span class="caption-text">The structure of SFLM.</span><a class="headerlink" href="#id1" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<p>The formal language <span class="math notranslate nohighlight">\(L\)</span> to be modeled is defined as</p>
<div class="math notranslate nohighlight">
\[L = \{w | |w| \leq 20, |w|_a + |w|_b = |w|_c, w\in \Sigma^*\}, \Sigma=\{a, b, c\}.\]</div>
<p>For example, <span class="math notranslate nohighlight">\(aabbcccc\in L\)</span>, while <span class="math notranslate nohighlight">\(cccab\notin L\)</span>.</p>
<p>The goal is to train a SFLM to fit <span class="math notranslate nohighlight">\(L\)</span> such that it can accurately generate <span class="math notranslate nohighlight">\(w\in L\)</span>.</p>
<section id="dependencies">
<h2>Dependencies<a class="headerlink" href="#dependencies" title="Link to this heading">¶</a></h2>
<p>To install dependencies for this Assignment, run</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>pip3<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements.txt
</pre></div>
</div>
<p>.</p>
</section>
<section id="tasks">
<h2>Tasks<a class="headerlink" href="#tasks" title="Link to this heading">¶</a></h2>
<p>The code skeleton is given. It consists of 4 files:</p>
<ul class="simple">
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">src/model.py</span></code>: It includes two pytorch modules:</dt><dd><ul>
<li><p><a class="reference internal" href="autoapi/model/index.html#model.SelfAttention" title="model.SelfAttention"><code class="xref py py-class docutils literal notranslate"><span class="pre">SelfAttention</span></code></a>: It defines the Self-Attention layer used in SFLM.</p></li>
<li><p><a class="reference internal" href="autoapi/model/index.html#model.SFLM" title="model.SFLM"><code class="xref py py-class docutils literal notranslate"><span class="pre">SFLM</span></code></a>: It defines the transformer illustrated in the <a class="reference internal" href="#structure"><span class="std std-ref">figure</span></a> above.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">src/utils.py</span></code>: It includes two helper classes:</dt><dd><ul>
<li><p><a class="reference internal" href="autoapi/utils/index.html#utils.LangABC" title="utils.LangABC"><code class="xref py py-class docutils literal notranslate"><span class="pre">LangABC</span></code></a>: It’s a Dummy dataset to generate <span class="math notranslate nohighlight">\(w\in L\)</span> online.</p></li>
<li><p><a class="reference internal" href="autoapi/utils/index.html#utils.TokenizerABC" title="utils.TokenizerABC"><code class="xref py py-class docutils literal notranslate"><span class="pre">TokenizerABC</span></code></a>: It’s a simple predefined tokenizer which translates between human-readable strings and SFLM-readable token indices</p></li>
</ul>
</dd>
</dl>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">train.py</span></code>: A script for training a SFLM to fit <span class="math notranslate nohighlight">\(L\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">infer.py</span></code>: A script for using a saved SFLM to conditionally generate <span class="math notranslate nohighlight">\(w\in L\)</span> in an interactive way.</p></li>
</ul>
<p>Your tasks in this assignment are:</p>
<ol class="arabic simple">
<li><p>Complete the forward functions of the two modules in the <code class="docutils literal notranslate"><span class="pre">src/model.py</span></code> file.
You can refer to their API documentations for their functionalities:</p>
<ul class="simple">
<li><p><a class="reference internal" href="autoapi/model/index.html#model.SelfAttention.forward" title="model.SelfAttention.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">model.SelfAttention.forward()</span></code></a>,</p></li>
<li><p><a class="reference internal" href="autoapi/model/index.html#model.SFLM.forward" title="model.SFLM.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">model.SFLM.forward()</span></code></a>.</p></li>
</ul>
</li>
<li><p>Train a SFLM to fit <span class="math notranslate nohighlight">\(L\)</span> with the <code class="docutils literal notranslate"><span class="pre">train.py</span></code> script.</p></li>
</ol>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="autoapi/index.html">API Reference</a></li>
</ul>
</div>
</section>
<section id="usage">
<h2>Usage<a class="headerlink" href="#usage" title="Link to this heading">¶</a></h2>
<p>After you have <strong>finished</strong> the two <code class="docutils literal notranslate"><span class="pre">forward</span></code> functions in the <code class="docutils literal notranslate"><span class="pre">model.py</span></code> file, you can train your SFLM with the default options by running</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>python3<span class="w"> </span>train.py
</pre></div>
</div>
<p>.</p>
<blockquote>
<div><figure class="align-default" id="id2">
<span id="sflm-train"></span><a class="reference internal image-reference" href="_images/SFLM_teacher_forcing.png"><img alt="_images/SFLM_teacher_forcing.png" src="_images/SFLM_teacher_forcing.png" style="width: 75%;" />
</a>
<figcaption>
<p><span class="caption-text">The <code class="docutils literal notranslate"><span class="pre">train.py</span></code> file applies teacher forcing to train the SFLM.</span><a class="headerlink" href="#id2" title="Link to this image">¶</a></p>
</figcaption>
</figure>
</div></blockquote>
<p>For more available configurations, check</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>python3<span class="w"> </span>train.py<span class="w"> </span>-h
</pre></div>
</div>
<p>.</p>
<p>With the default setting, the training should finish within an hour even on CPU.
Once the training is done, the model would be saved in <code class="docutils literal notranslate"><span class="pre">model.sav</span></code> file by default.</p>
<p>You can interact with your saved model, by run</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>python3<span class="w"> </span>infer.py
</pre></div>
</div>
<p>.</p>
<p>This will load model from the default path. To specify the model file, run</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>python3<span class="w"> </span>infer.py<span class="w"> </span>--save-path<span class="w"> </span>&lt;path_to_your_model&gt;
</pre></div>
</div>
<p>.</p>
</section>
<section id="submission-grading">
<h2>Submission&amp;Grading<a class="headerlink" href="#submission-grading" title="Link to this heading">¶</a></h2>
<p>Please pack your finished <strong>model.py</strong> file and saved <strong>model.sav</strong> file
in a zip file and submit through canvas.</p>
<p>The TA will check your code and test your trained model. Your assignment would be graded
based on your code quality, and also the output quality of your model.</p>
</section>
</section>


          </div>
          
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2025, COMP5212.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.2.3</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
      |
      <a href="_sources/index.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>