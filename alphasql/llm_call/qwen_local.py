from typing import List, Optional
import time
import requests
import logging
import os

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.ERROR)
logger = logging.getLogger(__name__)

def call_ollama_qwen(prompt: str,
              model: str = "qwen2.5-coder:7b-instruct",
              temperature: float = 0.0,
              top_p: float = 1.0,
              n: int = 1,
              max_tokens: int = 512,
              stop: List[str] = [],
              base_url: str = "http://localhost:11435",
              cost_recorder = None) -> str:
    """
    é€‚é…å™¨ç‰ˆæœ¬ï¼šä¿æŒ vLLM è°ƒç”¨æ ¼å¼ï¼Œå†…éƒ¨è½¬æ¢åˆ° Ollama åŸç”Ÿ API
    """
    MAX_RETRYING_TIMES = 5
    
    retrying = 0
    while retrying < MAX_RETRYING_TIMES:
        try:
            # å…ˆå°è¯• OpenAI å…¼å®¹æ¥å£
            try:
                url = f"{base_url}/v1/chat/completions"
                payload = {
                    "model": model,
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": temperature,
                    "max_tokens": max_tokens,
                    "n": n,
                    "top_p": top_p,
                    "stop": stop,
                    "stream": False
                }
                
                response = requests.post(url, json=payload, timeout=60)
                response.raise_for_status()
                result = response.json()
                
                if "choices" in result and len(result["choices"]) > 0:
                    return result["choices"][0]["message"]["content"]
                    
            except requests.exceptions.RequestException:
                # å¦‚æœ OpenAI æ¥å£å¤±è´¥ï¼Œå›é€€åˆ° Ollama åŸç”Ÿ API
                url = f"{base_url}/api/chat"
                payload = {
                    "model": model,
                    "messages": [{"role": "user", "content": prompt}],
                    "options": {
                        "temperature": temperature,
                        "top_p": top_p,
                        "num_predict": max_tokens,
                        "stop": stop
                    },
                    "stream": False
                }
                
                response = requests.post(url, json=payload, timeout=60)
                response.raise_for_status()
                result = response.json()
                
                if "message" in result and "content" in result["message"]:
                    return result["message"]["content"]
                else:
                    raise Exception("Ollama åŸç”Ÿ API å“åº”æ ¼å¼é”™è¯¯")
            
        except Exception as e:
            print(f"è°ƒç”¨é”™è¯¯: {e}")
            retrying += 1
            if retrying == MAX_RETRYING_TIMES:
                raise e
            time.sleep(10)
            
def call_vllm1(prompt: str,
              model: str = "Qwen2.5-Coder-7B-Instruct",
              temperature: float = 0.0,
              top_p: float = 1.0,
              n: int = 1,
              max_tokens: int = 512,
              stop: List[str] = [],
              base_url: str = "http://localhost:9999",  # ä¿®æ”¹åŸºç¡€URLï¼Œç§»é™¤/v1
              cost_recorder = None) -> str:
    # call vllm
    MAX_RETRYING_TIMES = 5
    
    retrying = 0
    while retrying < MAX_RETRYING_TIMES:
        try:
            url = f"{base_url}/v1/chat/completions"
            
            payload = {
                "model": model,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": temperature,
                "max_tokens": max_tokens,
                "n": n,
                "top_p": top_p,
                "stop": stop,
            }
            
            response = requests.post(url, json=payload)
            
            response.raise_for_status()  # è§¦å‘HTTPé”™è¯¯
            result = response.json()
            
            if "choices" in result and len(result["choices"]) > 0:
                return result["choices"][0]["message"]["content"]
            else:
                raise Exception("å“åº”ä¸­æ²¡æœ‰æœ‰æ•ˆçš„choiceså­—æ®µ")
            
        except Exception as e:
            print("-" * 100)
            print(f"è°ƒç”¨vLLMé”™è¯¯: {e}")
            print(f"å¼€å§‹ç¬¬ {retrying + 1} æ¬¡é‡è¯•")
            print("-" * 100)
            retrying += 1
            if retrying == MAX_RETRYING_TIMES:
                logger.error(f"ç»è¿‡ {MAX_RETRYING_TIMES} æ¬¡é‡è¯•åä»å‡ºé”™: {e}")
                raise e
            time.sleep(10)

def call_vllm(prompt: str,
              model: str = "Qwen2.5-Coder-7B-Instruct",
              temperature: float = 0.0,
              top_p: float = 1.0,
              n: int = 1,
              max_tokens: int = 512,
              stop: List[str] = [],
              base_url: str = "http://localhost:9999",
              cost_recorder = None) -> str:
    # call vllm
    MAX_RETRYING_TIMES = 5
    
    retrying = 0
    while retrying < MAX_RETRYING_TIMES:
        try:
            url = f"{base_url}/v1/chat/completions"
            
            # ä»ç¯å¢ƒå˜é‡è¯»å– API Key
            api_key = os.getenv('OPENAI_API_KEY')
            
            # æ„å»ºè¯·æ±‚å¤´
            headers = {
                "Content-Type": "application/json"
            }
            if api_key:
                headers["Authorization"] = f"Bearer {api_key}"
            
            payload = {
                "model": model,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": temperature,
                "max_tokens": max_tokens,
                "n": n,
                "top_p": top_p,
                "stop": stop,
            }
            
            response = requests.post(url, json=payload, headers=headers)
            
            response.raise_for_status()  # è§¦å‘HTTPé”™è¯¯
            result = response.json()
            
            if "choices" in result and len(result["choices"]) > 0:
                return result["choices"][0]["message"]["content"]
            else:
                raise Exception("å“åº”ä¸­æ²¡æœ‰æœ‰æ•ˆçš„choiceså­—æ®µ")
            
        except Exception as e:
            print("-" * 100)
            print(f"è°ƒç”¨vLLMé”™è¯¯: {e}")
            print(f"å¼€å§‹ç¬¬ {retrying + 1} æ¬¡é‡è¯•")
            print("-" * 100)
            retrying += 1
            if retrying == MAX_RETRYING_TIMES:
                logger.error(f"ç»è¿‡ {MAX_RETRYING_TIMES} æ¬¡é‡è¯•åä»å‡ºé”™: {e}")
                raise e
            time.sleep(10)

class OllamaEmbeddings:
    """OllamaåµŒå…¥å®¢æˆ·ç«¯ - å®Œæ•´ä¿®æ­£ç‰ˆ"""
    
    def __init__(self, base_url: str = "http://localhost:11434", model: str = "nomic-embed-text:latest"):
        self.base_url = base_url
        self.model = model
        self._verify_connection()
    
    def _verify_connection(self):
        """éªŒè¯è¿æ¥å’Œæ¨¡å‹å¯ç”¨æ€§"""
        print("ğŸ” éªŒè¯Ollamaè¿æ¥...")
        
        # 1. æ£€æŸ¥æœåŠ¡æ˜¯å¦è¿è¡Œ
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=10)
            if response.status_code == 200:
                print("âœ… OllamaæœåŠ¡è¿è¡Œæ­£å¸¸")
            else:
                print(f"âŒ OllamaæœåŠ¡å¼‚å¸¸: {response.status_code}")
                return False
        except Exception as e:
            print(f"âŒ æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡: {e}")
            return False
        
        # 2. æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨
        try:
            models_response = requests.get(f"{self.base_url}/api/tags", timeout=10)
            if models_response.status_code == 200:
                models_data = models_response.json()
                available_models = [model.get("name", "") for model in models_data.get("models", [])]
                
                if self.model in available_models:
                    print(f"âœ… æ¨¡å‹ '{self.model}' å¯ç”¨")
                else:
                    print(f"âŒ æ¨¡å‹ '{self.model}' æœªæ‰¾åˆ°")
                    print(f"   å¯ç”¨æ¨¡å‹: {available_models}")
                    print(f"   è¯·è¿è¡Œ: ollama pull {self.model}")
                    return False
            else:
                print(f"âŒ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {models_response.status_code}")
                return False
                
        except Exception as e:
            print(f"âŒ æ¨¡å‹æ£€æŸ¥å¤±è´¥: {e}")
            return False
        
        # 3. æµ‹è¯•embeddings API
        try:
            test_payload = {
                "model": self.model,
                "prompt": "test connection"
            }
            test_response = requests.post(
                f"{self.base_url}/api/embeddings",
                json=test_payload,
                timeout=15
            )
            
            if test_response.status_code == 200:
                result = test_response.json()
                embedding_dim = len(result.get("embedding", []))
                print(f"âœ… Embeddings API æµ‹è¯•æˆåŠŸ - ç»´åº¦: {embedding_dim}")
                return True
            else:
                print(f"âŒ Embeddings API æµ‹è¯•å¤±è´¥: {test_response.status_code}")
                print(f"   å“åº”: {test_response.text}")
                return False
                
        except Exception as e:
            print(f"âŒ Embeddings API æµ‹è¯•å¼‚å¸¸: {e}")
            return False
        
        return True
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """ä¸ºæ–‡æ¡£åˆ—è¡¨ç”ŸæˆåµŒå…¥"""
        embeddings = []
        fallback_count = 0
        
        for i, text in enumerate(texts):
            try:
                # å‡†å¤‡è¯·æ±‚
                url = f"{self.base_url}/api/embeddings"
                payload = {
                    "model": self.model,
                    "prompt": text
                }
                
                # å‘é€è¯·æ±‚
                response = requests.post(
                    url,
                    json=payload,
                    headers={'Content-Type': 'application/json'},
                    timeout=30
                )
                
                # æ£€æŸ¥å“åº”
                if response.status_code == 200:
                    result = response.json()
                    if "embedding" in result:
                        embedding_vector = result["embedding"]
                        embeddings.append(embedding_vector)
                        
                        # æ˜¾ç¤ºè¿›åº¦ï¼ˆå¯¹äºå¤§é‡æ–‡æœ¬ï¼‰
                        if len(texts) > 10 and i % 10 == 0:
                            print(f"ğŸ“Š åµŒå…¥è¿›åº¦: {i+1}/{len(texts)}")
                    else:
                        raise ValueError("å“åº”ä¸­ç¼ºå°‘embeddingå­—æ®µ")
                else:
                    raise Exception(f"APIè¿”å›çŠ¶æ€ç : {response.status_code}, å“åº”: {response.text}")
                    
            except Exception as e:
                print(f"âš ï¸ åµŒå…¥ç”Ÿæˆå¤±è´¥ (æ–‡æœ¬ {i+1}/{len(texts)}): {e}")
                fallback_embedding = self._fallback_embedding(text)
                embeddings.append(fallback_embedding)
                fallback_count += 1
        
        # æ€»ç»“æŠ¥å‘Š
        if fallback_count > 0:
            print(f"âš ï¸ è­¦å‘Š: {fallback_count}/{len(texts)} ä¸ªåµŒå…¥ä½¿ç”¨äº†é™çº§æ–¹æ¡ˆ")
        else:
            print(f"âœ… æ‰€æœ‰ {len(texts)} ä¸ªåµŒå…¥ç”ŸæˆæˆåŠŸ")
            
        return embeddings
    
    def embed_query(self, text: str) -> List[float]:
        """ä¸ºå•ä¸ªæŸ¥è¯¢ç”ŸæˆåµŒå…¥"""
        return self.embed_documents([text])[0]
    
    def _fallback_embedding(self, text: str, dimensions: int = 768) -> List[float]:
        """é™çº§åµŒå…¥æ–¹æ¡ˆ - åŸºäºæ–‡æœ¬å“ˆå¸Œç”Ÿæˆç¡®å®šæ€§éšæœºå‘é‡"""
        try:
            # ä½¿ç”¨MD5å“ˆå¸Œç”Ÿæˆç¡®å®šæ€§ç§å­
            hash_obj = hashlib.md5(text.encode('utf-8'))
            hash_hex = hash_obj.hexdigest()
            seed = int(hash_hex[:8], 16)
            
            # ä½¿ç”¨ç§å­ç”Ÿæˆç¡®å®šæ€§éšæœºå‘é‡
            np.random.seed(seed)
            embedding = np.random.normal(0, 1, dimensions)
            
            return embedding.tolist()
            
        except Exception as e:
            print(f"é™çº§åµŒå…¥å¤±è´¥: {e}")
            # ç»ˆæé™çº§æ–¹æ¡ˆ - é›¶å‘é‡
            return [0.0] * dimensions
    
    def get_embedding_dimension(self) -> int:
        """è·å–åµŒå…¥å‘é‡çš„ç»´åº¦"""
        try:
            test_embedding = self.embed_query("test")
            return len(test_embedding)
        except:
            return 768  # é»˜è®¤ç»´åº¦
    
    def batch_embed(self, texts: List[str], batch_size: int = 32) -> List[List[float]]:
        """æ‰¹é‡å¤„ç†åµŒå…¥ï¼ˆä¿ç•™æ–¹æ³•ç”¨äºæœªæ¥ä¼˜åŒ–ï¼‰"""
        print(f"ğŸ”„ æ‰¹é‡å¤„ç† {len(texts)} ä¸ªæ–‡æœ¬ï¼Œæ‰¹æ¬¡å¤§å°: {batch_size}")
        
        all_embeddings = []
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            print(f"å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}/{(len(texts)-1)//batch_size + 1}")
            
            batch_embeddings = self.embed_documents(batch)
            all_embeddings.extend(batch_embeddings)
        
        return all_embeddings

    """OllamaåµŒå…¥å®¢æˆ·ç«¯ - ä¿®æ­£ç‰ˆ"""
    def __init__(self, base_url="http://localhost:11434", model="nomic-embed-text"):
        self.base_url = base_url
        self.model = model
        self._verify_model()
    
    def _verify_model(self):
        """éªŒè¯æ¨¡å‹æ˜¯å¦å­˜åœ¨"""
        try:
            # å…ˆå°è¯•è°ƒç”¨ä¸€æ¬¡ï¼Œçœ‹æ¨¡å‹æ˜¯å¦å¯ç”¨
            test_response = requests.post(
                f"{self.base_url}/api/embeddings",
                json={"model": self.model, "prompt": "test"},
                timeout=10
            )
            if test_response.status_code == 200:
                print(f"âœ… æ¨¡å‹ {self.model} éªŒè¯æˆåŠŸ")
            else:
                print(f"âš ï¸ æ¨¡å‹ {self.model} å¯èƒ½æœ‰é—®é¢˜: {test_response.status_code}")
        except Exception as e:
            print(f"âŒ æ¨¡å‹éªŒè¯å¤±è´¥: {e}")
            print(f"è¯·ç¡®ä¿å·²è¿è¡Œ: ollama pull {self.model}")
    
    def embed_documents(self, texts):
        """ä¸ºæ–‡æ¡£åˆ—è¡¨ç”ŸæˆåµŒå…¥"""
        embeddings = []
        for text in texts:
            try:
                response = requests.post(
                    f"{self.base_url}/api/embeddings",
                    json={"model": self.model, "prompt": text},
                    timeout=30
                )
                response.raise_for_status()
                result = response.json()
                embeddings.append(result["embedding"])
            except Exception as e:
                print(f"åµŒå…¥ç”Ÿæˆå¤±è´¥: {e}")
                embeddings.append(self._fallback_embedding(text))
        return embeddings
    
    def embed_query(self, text):
        """ä¸ºå•ä¸ªæŸ¥è¯¢ç”ŸæˆåµŒå…¥"""
        return self.embed_documents([text])[0]
    
    def _fallback_embedding(self, text):
        """é™çº§åµŒå…¥æ–¹æ¡ˆ"""
        import hashlib
        import numpy as np
        hash_obj = hashlib.md5(text.encode())
        hash_int = int(hash_obj.hexdigest()[:8], 16)
        np.random.seed(hash_int)
        return np.random.normal(0, 1, 768).tolist()
    

if __name__ == "__main__":
    # æµ‹è¯•å‡½æ•°
    test_prompt = "Hello, how are you?"
    try:
        result = call_vllm(test_prompt)
        print("âœ… è°ƒç”¨æˆåŠŸ!")
        print(f"å“åº”: {result}")
    except Exception as e:
        print(f"âŒ è°ƒç”¨å¤±è´¥: {e}")
        