{
  "california_schools": {
    "predicted_sql": {
      "count": 4900,
      "mean_time": 0.008004384965312724,
      "std_time": 0.005487892828730107,
      "min_time": 0.00010967254638671875,
      "max_time": 0.03396773338317871
    },
    "ground_truth_sql": {
      "count": 4900,
      "mean_time": 0.007592974147018121,
      "std_time": 0.005974899681966965,
      "min_time": 0.00011801719665527344,
      "max_time": 0.10290026664733887
    }
  },
  "financial": {
    "predicted_sql": {
      "count": 6100,
      "mean_time": 0.006190627402946597,
      "std_time": 0.023256712386872446,
      "min_time": 7.390975952148438e-05,
      "max_time": 0.1571059226989746
    },
    "ground_truth_sql": {
      "count": 6100,
      "mean_time": 0.023602024961690435,
      "std_time": 0.08803971841354595,
      "min_time": 7.534027099609375e-05,
      "max_time": 0.5194923877716064
    }
  },
  "toxicology": {
    "predicted_sql": {
      "count": 9500,
      "mean_time": 0.0011433894006829513,
      "std_time": 0.00319257916229197,
      "min_time": 5.340576171875e-05,
      "max_time": 0.03282046318054199
    },
    "ground_truth_sql": {
      "count": 9500,
      "mean_time": 0.000815782998737536,
      "std_time": 0.001121421567488841,
      "min_time": 5.245208740234375e-05,
      "max_time": 0.00816202163696289
    }
  },
  "card_games": {
    "predicted_sql": {
      "count": 11700,
      "mean_time": 0.051282502056187035,
      "std_time": 0.07383054449162063,
      "min_time": 0.00011658668518066406,
      "max_time": 0.5855076313018799
    },
    "ground_truth_sql": {
      "count": 11700,
      "mean_time": 0.052417440292162776,
      "std_time": 0.07283787715293377,
      "min_time": 0.0001232624053955078,
      "max_time": 0.5351362228393555
    }
  },
  "codebase_community": {
    "predicted_sql": {
      "count": 12500,
      "mean_time": 0.0839317130279541,
      "std_time": 0.13088949241098302,
      "min_time": 0.00011754035949707031,
      "max_time": 0.6870384216308594
    },
    "ground_truth_sql": {
      "count": 12500,
      "mean_time": 0.08127793050765991,
      "std_time": 0.12978788166639937,
      "min_time": 0.00011324882507324219,
      "max_time": 0.8827223777770996
    }
  },
  "superhero": {
    "predicted_sql": {
      "count": 11500,
      "mean_time": 0.00029103291552999745,
      "std_time": 0.00039808763516132836,
      "min_time": 7.152557373046875e-05,
      "max_time": 0.004578590393066406
    },
    "ground_truth_sql": {
      "count": 11500,
      "mean_time": 0.0002747298323589822,
      "std_time": 0.0003647452694473739,
      "min_time": 7.224082946777344e-05,
      "max_time": 0.00373077392578125
    }
  },
  "formula_1": {
    "predicted_sql": {
      "count": 10100,
      "mean_time": 0.0021232016959992967,
      "std_time": 0.005772994404025748,
      "min_time": 0.00013446807861328125,
      "max_time": 0.04386091232299805
    },
    "ground_truth_sql": {
      "count": 10100,
      "mean_time": 0.0016134740574525134,
      "std_time": 0.004491768507771439,
      "min_time": 0.00013446807861328125,
      "max_time": 0.04198908805847168
    }
  },
  "european_football_2": {
    "predicted_sql": {
      "count": 9100,
      "mean_time": 0.06627946117422083,
      "std_time": 0.07701603231568352,
      "min_time": 0.0001747608184814453,
      "max_time": 0.28548717498779297
    },
    "ground_truth_sql": {
      "count": 9100,
      "mean_time": 0.0691587920503302,
      "std_time": 0.0778330924601129,
      "min_time": 0.00018167495727539062,
      "max_time": 0.2992565631866455
    }
  },
  "thrombosis_prediction": {
    "predicted_sql": {
      "count": 8700,
      "mean_time": 0.0007116360773985413,
      "std_time": 0.0009107888542871206,
      "min_time": 7.796287536621094e-05,
      "max_time": 0.013709306716918945
    },
    "ground_truth_sql": {
      "count": 8700,
      "mean_time": 0.0006849177130337419,
      "std_time": 0.0008557006659282129,
      "min_time": 7.915496826171875e-05,
      "max_time": 0.005341053009033203
    }
  },
  "student_club": {
    "predicted_sql": {
      "count": 13400,
      "mean_time": 0.00016633782813798136,
      "std_time": 0.00043998239118575437,
      "min_time": 7.295608520507812e-05,
      "max_time": 0.005228281021118164
    },
    "ground_truth_sql": {
      "count": 13400,
      "mean_time": 0.00016564604061753002,
      "std_time": 0.0004391884902662906,
      "min_time": 7.271766662597656e-05,
      "max_time": 0.005125999450683594
    }
  },
  "debit_card_specializing": {
    "predicted_sql": {
      "count": 4000,
      "mean_time": 0.018456724047660827,
      "std_time": 0.03738232835837884,
      "min_time": 7.128715515136719e-05,
      "max_time": 0.1656053066253662
    },
    "ground_truth_sql": {
      "count": 4000,
      "mean_time": 0.014117769837379456,
      "std_time": 0.030367239715303928,
      "min_time": 6.890296936035156e-05,
      "max_time": 0.18395471572875977
    }
  }
}