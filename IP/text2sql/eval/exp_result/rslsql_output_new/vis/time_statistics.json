{
  "california_schools": {
    "predicted_sql": {
      "count": 5300,
      "mean_time": 0.01727818785973315,
      "std_time": 0.07235346469144743,
      "min_time": 0.00010728836059570312,
      "max_time": 1.598721981048584
    },
    "ground_truth_sql": {
      "count": 5300,
      "mean_time": 0.007657412987835003,
      "std_time": 0.005602089837943372,
      "min_time": 0.00010967254638671875,
      "max_time": 0.047496795654296875
    }
  },
  "financial": {
    "predicted_sql": {
      "count": 6600,
      "mean_time": 0.025611542932914965,
      "std_time": 0.10855720514393037,
      "min_time": 7.224082946777344e-05,
      "max_time": 0.6917939186096191
    },
    "ground_truth_sql": {
      "count": 6600,
      "mean_time": 0.02908299814571034,
      "std_time": 0.11496156180364162,
      "min_time": 7.271766662597656e-05,
      "max_time": 0.6690688133239746
    }
  },
  "toxicology": {
    "predicted_sql": {
      "count": 9200,
      "mean_time": 0.0010377880283024,
      "std_time": 0.00169939028754993,
      "min_time": 5.2928924560546875e-05,
      "max_time": 0.012710332870483398
    },
    "ground_truth_sql": {
      "count": 9200,
      "mean_time": 0.0009091032587963602,
      "std_time": 0.0014796552353392414,
      "min_time": 5.4836273193359375e-05,
      "max_time": 0.014014959335327148
    }
  },
  "card_games": {
    "predicted_sql": {
      "count": 12000,
      "mean_time": 0.05686073178052902,
      "std_time": 0.0864981731057425,
      "min_time": 0.00011944770812988281,
      "max_time": 0.63149094581604
    },
    "ground_truth_sql": {
      "count": 12000,
      "mean_time": 0.0574159734249115,
      "std_time": 0.0851701500703192,
      "min_time": 0.0001220703125,
      "max_time": 0.605811595916748
    }
  },
  "codebase_community": {
    "predicted_sql": {
      "count": 12500,
      "mean_time": 0.14578863983154297,
      "std_time": 0.654354788514429,
      "min_time": 0.00012230873107910156,
      "max_time": 7.464250326156616
    },
    "ground_truth_sql": {
      "count": 12500,
      "mean_time": 0.13098313795089722,
      "std_time": 0.5066103268937128,
      "min_time": 0.00011968612670898438,
      "max_time": 5.791860580444336
    }
  },
  "superhero": {
    "predicted_sql": {
      "count": 11700,
      "mean_time": 0.0002509643277551374,
      "std_time": 0.00029909780225582266,
      "min_time": 7.081031799316406e-05,
      "max_time": 0.002905130386352539
    },
    "ground_truth_sql": {
      "count": 11700,
      "mean_time": 0.000253852106567122,
      "std_time": 0.000304036218183623,
      "min_time": 7.152557373046875e-05,
      "max_time": 0.0027496814727783203
    }
  },
  "formula_1": {
    "predicted_sql": {
      "count": 10300,
      "mean_time": 0.002268367994178846,
      "std_time": 0.006175667349663919,
      "min_time": 0.00013136863708496094,
      "max_time": 0.049103736877441406
    },
    "ground_truth_sql": {
      "count": 10300,
      "mean_time": 0.002136739480842664,
      "std_time": 0.005988945674282514,
      "min_time": 0.00013208389282226562,
      "max_time": 0.04743766784667969
    }
  },
  "european_football_2": {
    "predicted_sql": {
      "count": 9100,
      "mean_time": 0.0667227761562054,
      "std_time": 0.07611458403857166,
      "min_time": 0.00017690658569335938,
      "max_time": 0.3637971878051758
    },
    "ground_truth_sql": {
      "count": 9100,
      "mean_time": 0.0688938019825862,
      "std_time": 0.07590818003358583,
      "min_time": 0.0001862049102783203,
      "max_time": 0.3674919605255127
    }
  },
  "thrombosis_prediction": {
    "predicted_sql": {
      "count": 8900,
      "mean_time": 0.0007816647679618235,
      "std_time": 0.0010493279575126398,
      "min_time": 7.510185241699219e-05,
      "max_time": 0.01423788070678711
    },
    "ground_truth_sql": {
      "count": 8900,
      "mean_time": 0.0007720463731315699,
      "std_time": 0.0009671343991864636,
      "min_time": 7.462501525878906e-05,
      "max_time": 0.006428956985473633
    }
  },
  "student_club": {
    "predicted_sql": {
      "count": 12800,
      "mean_time": 0.00017312686890363693,
      "std_time": 0.00047593797504721924,
      "min_time": 7.224082946777344e-05,
      "max_time": 0.0045506954193115234
    },
    "ground_truth_sql": {
      "count": 12800,
      "mean_time": 0.00017099710181355476,
      "std_time": 0.0004721270250909346,
      "min_time": 7.2479248046875e-05,
      "max_time": 0.0044820308685302734
    }
  },
  "debit_card_specializing": {
    "predicted_sql": {
      "count": 4100,
      "mean_time": 0.021077297780571914,
      "std_time": 0.04392961434749074,
      "min_time": 6.318092346191406e-05,
      "max_time": 0.21589970588684082
    },
    "ground_truth_sql": {
      "count": 4100,
      "mean_time": 0.018072484004788284,
      "std_time": 0.038548290616890114,
      "min_time": 6.794929504394531e-05,
      "max_time": 0.18942713737487793
    }
  }
}