import sys
sys.path.append('/ssddata/zzhangle/Alpha-SQL') 

import pickle
import json
from pathlib import Path
import glob
import os

def extract_sql_from_pkl(pkl_file_path):
    """
    ä»pklæ–‡ä»¶ä¸­æå–æ‰€æœ‰è·¯å¾„çš„æœ€ç»ˆSQL
    """
    try:
        with open(pkl_file_path, 'rb') as f:
            data = pickle.load(f)
        
        sql_list = []
        
        if isinstance(data, list):
            for i, path in enumerate(data):
                if isinstance(path, list) and len(path) > 0:
                    # è·å–æœ€åä¸€ä¸ªèŠ‚ç‚¹çš„final_sql_query
                    last_node = path[-1]
                    if hasattr(last_node, 'final_sql_query') and last_node.final_sql_query:
                        sql_list.append(last_node.final_sql_query)
        
        return sql_list
        
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶ {pkl_file_path} æ—¶å‡ºé”™: {e}")
        return []

def extract_all_sql_from_directory(input_dir, output_file):
    """
    ä»ç›®å½•ä¸­æ‰€æœ‰pklæ–‡ä»¶æå–SQLå¹¶ä¿å­˜
    """
    # æŸ¥æ‰¾æ‰€æœ‰pklæ–‡ä»¶
    pkl_files = list(Path(input_dir).glob("*.pkl"))
    
    if not pkl_files:
        print(f"åœ¨ç›®å½• {input_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°pklæ–‡ä»¶")
        return {}
    
    print(f"æ‰¾åˆ° {len(pkl_files)} ä¸ªpklæ–‡ä»¶ï¼Œå¼€å§‹æå–SQL...")
    
    sql_dict = {}
    
    for pkl_file in pkl_files:
        # è·å–æ–‡ä»¶åï¼ˆä¸å¸¦æ‰©å±•åï¼‰
        file_stem = pkl_file.stem
        
        # æå–SQL
        sql_list = extract_sql_from_pkl(str(pkl_file))
        sql_dict[file_stem] = sql_list
        
        print(f"âœ… {file_stem}.pkl: æå–åˆ° {len(sql_list)} ä¸ªSQL")
    
    # ä¿å­˜åˆ°JSONæ–‡ä»¶
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(sql_dict, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ‰ SQLæå–å®Œæˆï¼")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {output_file}")
    print(f"ğŸ“Š å…±å¤„ç†äº† {len(pkl_files)} ä¸ªæ–‡ä»¶")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    total_sql = sum(len(sql_list) for sql_list in sql_dict.values())
    print(f"ğŸ“ æ€»å…±æå–äº† {total_sql} ä¸ªSQLæŸ¥è¯¢")
    
    # æ˜¾ç¤ºæ¯ä¸ªæ–‡ä»¶çš„SQLæ•°é‡
    print(f"\nğŸ“‹ å„æ–‡ä»¶SQLæ•°é‡ç»Ÿè®¡:")
    for file_stem, sql_list in sorted(sql_dict.items()):
        print(f"  {file_stem}: {len(sql_list)} ä¸ªSQL")
    
    return sql_dict

def extract_sql_with_details(input_dir, output_file):
    """
    æå–SQLå¹¶åŒ…å«æ›´å¤šè¯¦ç»†ä¿¡æ¯
    """
    pkl_files = list(Path(input_dir).glob("*.pkl"))
    
    if not pkl_files:
        print(f"åœ¨ç›®å½• {input_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°pklæ–‡ä»¶")
        return {}
    
    detailed_dict = {}
    
    for pkl_file in pkl_files:
        file_stem = pkl_file.stem
        
        try:
            with open(pkl_file, 'rb') as f:
                data = pickle.load(f)
            
            sql_details = []
            
            if isinstance(data, list):
                for path_index, path in enumerate(data):
                    if isinstance(path, list) and len(path) > 0:
                        last_node = path[-1]
                        if hasattr(last_node, 'final_sql_query') and last_node.final_sql_query:
                            sql_details.append({
                                "path_index": path_index,
                                "sql": last_node.final_sql_query,
                                "path_length": len(path),
                                "node_type": last_node.node_type.value if hasattr(last_node, 'node_type') else "Unknown"
                            })
            
            detailed_dict[file_stem] = sql_details
            print(f"âœ… {file_stem}.pkl: {len(sql_details)} ä¸ªSQL")
            
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶ {pkl_file} æ—¶å‡ºé”™: {e}")
            detailed_dict[file_stem] = []
    
    # ä¿å­˜åˆ°JSONæ–‡ä»¶
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(detailed_dict, f, indent=2, ensure_ascii=False)
    
    return detailed_dict

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # é…ç½®è·¯å¾„
    input_dir = "results/Qwen2.5-Coder-32B-Instruct/bird/dev_300"
    out_dir = "logs/analysis/bird_300"
    output_file = f"{out_dir}/extracted_sql.json"
    os.makedirs(out_dir,exist_ok=True)
    
    # æ–¹æ³•1: ç®€å•æå–ï¼ˆåªä¿å­˜SQLåˆ—è¡¨ï¼‰
    print("æ–¹æ³•1: ç®€å•æå–SQL")
    print("=" * 40)
    sql_dict = extract_all_sql_from_directory(input_dir, output_file)
    
    print("\n" + "=" * 50)
    
    # æ–¹æ³•2: è¯¦ç»†æå–ï¼ˆåŒ…å«è·¯å¾„ä¿¡æ¯ï¼‰
    print("æ–¹æ³•2: è¯¦ç»†æå–SQL")
    print("=" * 40)
    detailed_output_file = f"{out_dir}/extracted_sql_detailed.json"
    detailed_dict = extract_sql_with_details(input_dir, detailed_output_file)
    
    # æ˜¾ç¤ºç¤ºä¾‹è¾“å‡ºç»“æ„
    if sql_dict:
        first_key = list(sql_dict.keys())[0]
        print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶ç»“æ„ç¤ºä¾‹:")
        print(f"æ–‡ä»¶: {output_file}")
        print(f"é”®: {first_key}")
        print(f"å€¼: {len(sql_dict[first_key])} ä¸ªSQLçš„åˆ—è¡¨")
        
        if sql_dict[first_key]:
            print(f"ç¬¬ä¸€ä¸ªSQLç¤ºä¾‹: {sql_dict[first_key][0][:100]}...")