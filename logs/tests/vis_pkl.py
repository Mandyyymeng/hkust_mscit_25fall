import json
import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from typing import Dict, List, Any, Tuple

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œæ ·å¼
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")

def load_data(detailed_json_path: str, answers_json_path: str, dev_json_path: str) -> Tuple[Dict, Dict, Dict]:
    """åŠ è½½æ•°æ®"""
    with open(detailed_json_path, 'r', encoding='utf-8') as f:
        detailed_data = json.load(f)
    
    with open(answers_json_path, 'r', encoding='utf-8') as f:
        answers_data = json.load(f)
    
    # æ–°å¢ï¼šåŠ è½½dev.jsonè·å–éš¾åº¦ä¿¡æ¯
    with open(dev_json_path, 'r', encoding='utf-8') as f:
        dev_data = json.load(f)
    
    # åˆ›å»ºquestion_idåˆ°difficultyçš„æ˜ å°„
    id_to_difficulty = {}
    for item in dev_data:
        id_to_difficulty[item["question_id"]] = item["difficulty"]
    
    return detailed_data, answers_data, id_to_difficulty

def normalize_sql(sql: str) -> str:
    """æ ‡å‡†åŒ–SQLå­—ç¬¦ä¸²ç”¨äºæ¯”è¾ƒ"""
    if not sql:
        return ""
    return ' '.join(sql.lower().split())

def compare_results(predicted_result, ground_truth_answer) -> Tuple[bool, bool]:
    """
    æ¯”è¾ƒé¢„æµ‹ç»“æœå’ŒçœŸå®ç­”æ¡ˆ
    è¿”å›: (å®Œå…¨åŒ¹é…, éƒ¨åˆ†åŒ¹é…)
    """
    if not predicted_result or not ground_truth_answer:
        return False, False
    
    # æå–é¢„æµ‹ç»“æœ
    pred_str = str(predicted_result).lower().strip()
    truth_str = str(ground_truth_answer).lower().strip()
    
    # å®Œå…¨åŒ¹é…
    exact_match = pred_str == truth_str
    
    # éƒ¨åˆ†åŒ¹é…ï¼šé¢„æµ‹ç»“æœåŒ…å«çœŸå®ç­”æ¡ˆ
    partial_match = truth_str in pred_str
    
    return exact_match, partial_match

def analyze_data(detailed_data: Dict, answers_data: Dict, id_to_difficulty: Dict) -> Dict[str, Any]:
    """åˆ†ææ•°æ®å¹¶è®¡ç®—æŒ‡æ ‡"""
    
    analysis_results = {
        'db_stats': {},
        'difficulty_stats': {},  # æ–°å¢ï¼šéš¾åº¦ç»Ÿè®¡
        'question_stats': {},
        'all_paths': []
    }
    
    # åˆå§‹åŒ–éš¾åº¦ç»Ÿè®¡
    difficulty_stats = analysis_results['difficulty_stats']
    
    # ç¬¬ä¸€éï¼šæ”¶é›†æ‰€æœ‰è·¯å¾„ä¿¡æ¯
    for qid, question_data in detailed_data.items():
        db_id = question_data['db_id']
        question_id = question_data['question_id']
        ground_truth = answers_data.get(str(question_id))
        
        # åˆå§‹åŒ–æ•°æ®åº“ç»Ÿè®¡
        if db_id not in analysis_results['db_stats']:
            analysis_results['db_stats'][db_id] = {
                'total_questions': 0,
                'exact_match_upper': 0,
                'partial_match_upper': 0,
                'selected_exact_match': 0,
                'selected_partial_match': 0,
                'path_lengths': [],
                'consistency_scores': []
            }
        
        db_stats = analysis_results['db_stats'][db_id]
        db_stats['total_questions'] += 1
        
        # åˆå§‹åŒ–éš¾åº¦ç»Ÿè®¡
        difficulty = id_to_difficulty.get(question_id, 'unknown')
        if difficulty not in difficulty_stats:
            difficulty_stats[difficulty] = {
                'total_questions': 0,
                'exact_match_upper': 0,
                'partial_match_upper': 0,
                'selected_exact_match': 0,
                'selected_partial_match': 0
            }
        
        diff_stats = difficulty_stats[difficulty]
        diff_stats['total_questions'] += 1
        
        # å¤„ç†æ¯ä¸ªè·¯å¾„
        selected_path_index = question_data.get('selected_path_index', 0)
        all_paths_info = question_data.get('all_paths_info', [])
        
        question_exact_match_upper = False
        question_partial_match_upper = False
        selected_exact_match = False
        selected_partial_match = False
        
        for path_info in all_paths_info:
            path_index = path_info['path_index']
            execution_result = path_info.get('execution_result', {})
            result_data = execution_result.get('result', [])
            
            # æå–ç¬¬ä¸€ä¸ªç»“æœ
            first_result = result_data[0][0] if result_data and len(result_data) > 0 and len(result_data[0]) > 0 else None
            
            # ä¸çœŸå®ç­”æ¡ˆæ¯”è¾ƒ
            exact_match, partial_match = compare_results(first_result, ground_truth)
            
            # æ›´æ–°upper bound
            if exact_match:
                question_exact_match_upper = True
            if partial_match:
                question_partial_match_upper = True
            
            # æ›´æ–°selected path
            if path_index == selected_path_index:
                selected_exact_match = exact_match
                selected_partial_match = partial_match
            
            # æ”¶é›†è·¯å¾„æ•°æ®
            path_data = {
                'db_id': db_id,
                'question_id': question_id,
                'path_index': path_index,
                'path_length': path_info.get('path_length', 0),
                'consistency_score': path_info.get('consistency_score', 0),
                'is_selected': path_index == selected_path_index,
                'exact_match': exact_match,
                'partial_match': partial_match,
                'difficulty': difficulty  # æ–°å¢éš¾åº¦å­—æ®µ
            }
            analysis_results['all_paths'].append(path_data)
        
        # æ›´æ–°æ•°æ®åº“ç»Ÿè®¡
        if question_exact_match_upper:
            db_stats['exact_match_upper'] += 1
        if question_partial_match_upper:
            db_stats['partial_match_upper'] += 1
        if selected_exact_match:
            db_stats['selected_exact_match'] += 1
        if selected_partial_match:
            db_stats['selected_partial_match'] += 1
        
        db_stats['path_lengths'].extend([p['path_length'] for p in all_paths_info])
        db_stats['consistency_scores'].extend([p['consistency_score'] for p in all_paths_info])
        
        # æ›´æ–°éš¾åº¦ç»Ÿè®¡ï¼ˆä¸db_statsç›¸åŒçš„é€»è¾‘ï¼‰
        if question_exact_match_upper:
            diff_stats['exact_match_upper'] += 1
        if question_partial_match_upper:
            diff_stats['partial_match_upper'] += 1
        if selected_exact_match:
            diff_stats['selected_exact_match'] += 1
        if selected_partial_match:
            diff_stats['selected_partial_match'] += 1
    
    return analysis_results
          
def create_visualizations(analysis_results: Dict, output_dir: str):
    """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # å‡†å¤‡æ•°æ®
    all_paths_df = pd.DataFrame(analysis_results['all_paths'])
    db_stats = analysis_results['db_stats']
    difficulty_stats = analysis_results['difficulty_stats']  # æ–°å¢ï¼šéš¾åº¦ç»Ÿè®¡
    
    # 1. æ•°æ®åº“å‡†ç¡®ç‡æ¯”è¾ƒæŸ±çŠ¶å›¾
    db_names = list(db_stats.keys())
    exact_match_upper = [db_stats[db]['exact_match_upper'] / db_stats[db]['total_questions'] for db in db_names]
    partial_match_upper = [db_stats[db]['partial_match_upper'] / db_stats[db]['total_questions'] for db in db_names]
    selected_exact_match = [db_stats[db]['selected_exact_match'] / db_stats[db]['total_questions'] for db in db_names]
    selected_partial_match = [db_stats[db]['selected_partial_match'] / db_stats[db]['total_questions'] for db in db_names]
    
    x = np.arange(len(db_names))
    width = 0.2
    
    plt.figure(figsize=(16, 10))
    bars1 = plt.bar(x - 1.5*width, exact_match_upper, width, label='Exact Match Upper Bound', alpha=0.8, color='skyblue')
    bars2 = plt.bar(x - 0.5*width, partial_match_upper, width, label='Partial Match Upper Bound', alpha=0.8, color='lightcoral')
    bars3 = plt.bar(x + 0.5*width, selected_exact_match, width, label='Selected Exact Match', alpha=0.8, color='lightgreen')
    bars4 = plt.bar(x + 1.5*width, selected_partial_match, width, label='Selected Partial Match', alpha=0.8, color='gold')
    
    # åœ¨æŸ±å­é¡¶ç«¯æ·»åŠ å‡†ç¡®ç‡æ–‡æœ¬
    for bars, values in zip([bars1, bars2, bars3, bars4], 
                           [exact_match_upper, partial_match_upper, selected_exact_match, selected_partial_match]):
        for bar, value in zip(bars, values):
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{value:.2f}', ha='center', va='bottom', fontsize=8, rotation=45)
    
    plt.xlabel('Database', fontsize=12)
    plt.ylabel('Accuracy', fontsize=12)
    plt.title('Accuracy Comparison by Database', fontsize=16, fontweight='bold')
    plt.xticks(x, db_names, rotation=45, ha='right')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'accuracy_comparison_by_db.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    # 2. æ–°å¢ï¼šéš¾åº¦å‡†ç¡®ç‡æ¯”è¾ƒæŸ±çŠ¶å›¾
    difficulties = list(difficulty_stats.keys())
    
    # æŒ‰éš¾åº¦æ’åºï¼ˆå¦‚æœæœ‰æ ‡å‡†é¡ºåºï¼‰
    difficulty_order = ['simple', 'moderate', 'challenging', 'unknown']
    difficulties = [d for d in difficulty_order if d in difficulties] + [d for d in difficulties if d not in difficulty_order]
    
    exact_match_upper_diff = [difficulty_stats[diff]['exact_match_upper'] / difficulty_stats[diff]['total_questions'] for diff in difficulties]
    partial_match_upper_diff = [difficulty_stats[diff]['partial_match_upper'] / difficulty_stats[diff]['total_questions'] for diff in difficulties]
    selected_exact_match_diff = [difficulty_stats[diff]['selected_exact_match'] / difficulty_stats[diff]['total_questions'] for diff in difficulties]
    selected_partial_match_diff = [difficulty_stats[diff]['selected_partial_match'] / difficulty_stats[diff]['total_questions'] for diff in difficulties]
    
    x_diff = np.arange(len(difficulties))
    width_diff = 0.2
    
    plt.figure(figsize=(14, 8))
    bars1_diff = plt.bar(x_diff - 1.5*width_diff, exact_match_upper_diff, width_diff, label='Exact Match Upper Bound', alpha=0.8, color='skyblue')
    bars2_diff = plt.bar(x_diff - 0.5*width_diff, partial_match_upper_diff, width_diff, label='Partial Match Upper Bound', alpha=0.8, color='lightcoral')
    bars3_diff = plt.bar(x_diff + 0.5*width_diff, selected_exact_match_diff, width_diff, label='Selected Exact Match', alpha=0.8, color='lightgreen')
    bars4_diff = plt.bar(x_diff + 1.5*width_diff, selected_partial_match_diff, width_diff, label='Selected Partial Match', alpha=0.8, color='gold')
    
    # åœ¨æŸ±å­é¡¶ç«¯æ·»åŠ å‡†ç¡®ç‡æ–‡æœ¬
    for bars, values in zip([bars1_diff, bars2_diff, bars3_diff, bars4_diff], 
                           [exact_match_upper_diff, partial_match_upper_diff, selected_exact_match_diff, selected_partial_match_diff]):
        for bar, value in zip(bars, values):
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{value:.2f}', ha='center', va='bottom', fontsize=9, rotation=0)
    
    plt.xlabel('Difficulty Level', fontsize=12)
    plt.ylabel('Accuracy', fontsize=12)
    plt.title('Accuracy Comparison by Difficulty Level', fontsize=16, fontweight='bold')
    plt.xticks(x_diff, [d.capitalize() for d in difficulties])
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.ylim(0, max(max(exact_match_upper_diff), max(partial_match_upper_diff), 
                   max(selected_exact_match_diff), max(selected_partial_match_diff)) + 0.1)
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'accuracy_comparison_by_difficulty.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    # 3. è·¯å¾„é•¿åº¦ä¸ä¸€è‡´æ€§å¾—åˆ†çš„å…³ç³»å›¾
    plt.figure(figsize=(12, 8))
    sns.scatterplot(data=all_paths_df, x='path_length', y='consistency_score', 
                   alpha=0.6, s=60)
    plt.title('Path Length vs Consistency Score', fontsize=16, fontweight='bold')
    plt.xlabel('Path Length')
    plt.ylabel('Consistency Score')
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'path_length_vs_consistency.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    # 4. æŒ‰æ•°æ®åº“åˆ†ç»„çš„è·¯å¾„é•¿åº¦ä¸ä¸€è‡´æ€§å¾—åˆ†
    plt.figure(figsize=(15, 10))
    sns.scatterplot(data=all_paths_df, x='path_length', y='consistency_score', 
                   hue='db_id', alpha=0.7, s=60)
    plt.title('Path Length vs Consistency Score by Database', fontsize=16, fontweight='bold')
    plt.xlabel('Path Length')
    plt.ylabel('Consistency Score')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'path_length_vs_consistency_by_db.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    # 5. æ€»ä½“ç»Ÿè®¡çƒ­åŠ›å›¾
    overall_stats = []
    for db in db_names:
        stats = db_stats[db]
        overall_stats.append({
            'Database': db,
            'Total Questions': stats['total_questions'],
            'Exact Match Upper': stats['exact_match_upper'] / stats['total_questions'],
            'Partial Match Upper': stats['partial_match_upper'] / stats['total_questions'],
            'Selected Exact Match': stats['selected_exact_match'] / stats['total_questions'],
            'Selected Partial Match': stats['selected_partial_match'] / stats['total_questions'],
            'Avg Path Length': np.mean(stats['path_lengths']),
            'Avg Consistency Score': np.mean(stats['consistency_scores'])
        })
    
    overall_df = pd.DataFrame(overall_stats)
    
    # çƒ­åŠ›å›¾æ•°æ®å‡†å¤‡
    heatmap_data = overall_df.set_index('Database')[['Exact Match Upper', 'Partial Match Upper', 
                                                    'Selected Exact Match', 'Selected Partial Match']]
    
    plt.figure(figsize=(12, 8))
    sns.heatmap(heatmap_data, annot=True, fmt='.3f', cmap='YlOrRd', cbar_kws={'label': 'Accuracy'})
    plt.title('Accuracy Metrics Heatmap by Database', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'accuracy_heatmap.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    # 6. è·¯å¾„é•¿åº¦åˆ†å¸ƒ
    plt.figure(figsize=(12, 8))
    sns.histplot(data=all_paths_df, x='path_length', bins=30, kde=True)
    plt.title('Distribution of Path Lengths', fontsize=16, fontweight='bold')
    plt.xlabel('Path Length')
    plt.ylabel('Frequency')
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'path_length_distribution.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    # 7. ä¸€è‡´æ€§å¾—åˆ†åˆ†å¸ƒ
    plt.figure(figsize=(12, 8))
    sns.histplot(data=all_paths_df, x='consistency_score', bins=30, kde=True)
    plt.title('Distribution of Consistency Scores', fontsize=16, fontweight='bold')
    plt.xlabel('Consistency Score')
    plt.ylabel('Frequency')
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'consistency_score_distribution.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    return overall_df

def save_csv_results(analysis_results: Dict, overall_df: pd.DataFrame, output_dir: str):
    """ä¿å­˜CSVç»“æœ"""
    
    # ä¿å­˜æ€»ä½“ç»Ÿè®¡
    overall_df.to_csv(os.path.join(output_dir, 'overall_statistics.csv'), index=False)
    
    # ä¿å­˜æ‰€æœ‰è·¯å¾„æ•°æ®
    all_paths_df = pd.DataFrame(analysis_results['all_paths'])
    all_paths_df.to_csv(os.path.join(output_dir, 'all_paths_data.csv'), index=False)
    
    # ä¿å­˜æ•°æ®åº“çº§åˆ«ç»Ÿè®¡
    db_stats_list = []
    for db, stats in analysis_results['db_stats'].items():
        db_stats_list.append({
            'Database': db,
            'Total Questions': stats['total_questions'],
            'Exact Match Upper Bound': stats['exact_match_upper'],
            'Partial Match Upper Bound': stats['partial_match_upper'],
            'Selected Exact Match': stats['selected_exact_match'],
            'Selected Partial Match': stats['selected_partial_match'],
            'Exact Match Upper Accuracy': stats['exact_match_upper'] / stats['total_questions'],
            'Partial Match Upper Accuracy': stats['partial_match_upper'] / stats['total_questions'],
            'Selected Exact Match Accuracy': stats['selected_exact_match'] / stats['total_questions'],
            'Selected Partial Match Accuracy': stats['selected_partial_match'] / stats['total_questions'],
            'Average Path Length': np.mean(stats['path_lengths']),
            'Average Consistency Score': np.mean(stats['consistency_scores'])
        })
    
    db_stats_df = pd.DataFrame(db_stats_list)
    db_stats_df.to_csv(os.path.join(output_dir, 'database_statistics.csv'), index=False)

def main():
    # æ–‡ä»¶è·¯å¾„é…ç½®
    detailed_json_path = 'logs/pred_sqls/pred_sqls_qwen32b_bird_300_detailed.json'
    answers_json_path = 'data/bird/dev/dev_answer.json'
    dev_json_path = 'data/bird/dev/dev_all.json'  # æ–°å¢ï¼šdev.jsonè·¯å¾„
    output_dir = 'vis_results'
    
    print("ğŸš€ å¼€å§‹æ•°æ®åˆ†æ...")
    
    # åŠ è½½æ•°æ®ï¼ˆä¿®æ”¹ä¸º3ä¸ªå‚æ•°ï¼‰
    print("ğŸ“‚ åŠ è½½æ•°æ®...")
    detailed_data, answers_data, id_to_difficulty = load_data(detailed_json_path, answers_json_path, dev_json_path)
    
    # åˆ†ææ•°æ®ï¼ˆä¿®æ”¹ä¸º3ä¸ªå‚æ•°ï¼‰
    print("ğŸ“Š åˆ†ææ•°æ®...")
    analysis_results = analyze_data(detailed_data, answers_data, id_to_difficulty)
    
    # åˆ›å»ºå¯è§†åŒ–
    print("ğŸ¨ åˆ›å»ºå¯è§†åŒ–å›¾è¡¨...")
    overall_df = create_visualizations(analysis_results, output_dir)
    
    # ä¿å­˜CSVç»“æœ
    print("ğŸ’¾ ä¿å­˜ç»“æœ...")
    save_csv_results(analysis_results, overall_df, output_dir)
    
    # æ‰“å°æ€»ä½“ç»Ÿè®¡
    print("\nğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
    print(f"æ€»æ•°æ®åº“æ•°é‡: {len(analysis_results['db_stats'])}")
    print(f"æ€»é—®é¢˜æ•°é‡: {len(detailed_data)}")
    print(f"æ€»è·¯å¾„æ•°é‡: {len(analysis_results['all_paths'])}")
    
    # è®¡ç®—æ€»ä½“å‡†ç¡®ç‡
    total_questions = sum([stats['total_questions'] for stats in analysis_results['db_stats'].values()])
    total_exact_upper = sum([stats['exact_match_upper'] for stats in analysis_results['db_stats'].values()])
    total_partial_upper = sum([stats['partial_match_upper'] for stats in analysis_results['db_stats'].values()])
    total_selected_exact = sum([stats['selected_exact_match'] for stats in analysis_results['db_stats'].values()])
    total_selected_partial = sum([stats['selected_partial_match'] for stats in analysis_results['db_stats'].values()])
    
    print(f"\nğŸ¯ æ€»ä½“å‡†ç¡®ç‡:")
    print(f"Exact Match Upper Bound: {total_exact_upper}/{total_questions} ({total_exact_upper/total_questions:.3f})")
    print(f"Partial Match Upper Bound: {total_partial_upper}/{total_questions} ({total_partial_upper/total_questions:.3f})")
    print(f"Selected Exact Match: {total_selected_exact}/{total_questions} ({total_selected_exact/total_questions:.3f})")
    print(f"Selected Partial Match: {total_selected_partial}/{total_questions} ({total_selected_partial/total_questions:.3f})")
    
    # æ–°å¢ï¼šéš¾åº¦ç»Ÿè®¡
    difficulty_stats = analysis_results['difficulty_stats']
    print(f"\nğŸ“Š éš¾åº¦ç»Ÿè®¡:")
    for difficulty, stats in difficulty_stats.items():
        total = stats['total_questions']
        if total > 0:
            exact_acc = stats['exact_match_upper'] / total
            partial_acc = stats['partial_match_upper'] / total
            selected_exact_acc = stats['selected_exact_match'] / total
            selected_partial_acc = stats['selected_partial_match'] / total
            print(f"{difficulty.capitalize()}: {total} questions")
            print(f"  Exact Upper: {exact_acc:.3f}, Partial Upper: {partial_acc:.3f}")
            print(f"  Selected Exact: {selected_exact_acc:.3f}, Selected Partial: {selected_partial_acc:.3f}")
    
    print(f"\nâœ… åˆ†æå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {output_dir}/")

if __name__ == "__main__":
    main()